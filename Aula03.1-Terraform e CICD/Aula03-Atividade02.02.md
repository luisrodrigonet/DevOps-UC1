# Aula 03 - Atividade 02.02
> **Terra Form - M√≥dulos e Estado** 
> - Criar m√≥dulo reutiliz√°vel para ambiente de an√°lise 
> - Configurar backend remoto (S3) 
> - Implementar workspaces 
> - Usar data sources para recursos existentes

Esta atividade aborda **m√≥dulos, estados, workspaces e data sources** no Terraform. Al√©m disso, simularemos um **backend remoto (S3) em infraestrutura local** usando Docker.  

A atividade ser√° desenvolvida tendo como base o Sistema Operacional Windows 10 ou 11

üìå **Tecnologias utilizadas**:  
- Terraform  
- Docker  
- Jupyter Notebook  
- PostgreSQL  
- MinIO (alternativa ao AWS S3)  

üìå **Requisitos**:  
- Windows 11  
- Docker Desktop instalado  
- Terraform instalado  
- AWS Cli

# **1. Introdu√ß√£o ao Terraform**  

O **Terraform** √© uma ferramenta de **Infraestrutura como C√≥digo (IaC)** que permite criar, gerenciar e versionar infraestrutura de forma declarativa.  

**Conceitos Importantes:**  
‚úîÔ∏è **M√≥dulos:** Permitem reutilizar c√≥digo para criar infraestruturas padronizadas.  
‚úîÔ∏è **Estado (State):** Mant√©m o rastreamento dos recursos criados pelo Terraform.  
‚úîÔ∏è **Backend Remoto:** Guarda o estado do Terraform em um servi√ßo externo (como AWS S3).  
‚úîÔ∏è **Workspaces:** Permitem criar m√∫ltiplas inst√¢ncias de uma mesma configura√ß√£o.  
‚úîÔ∏è **Data Sources:** Permitem acessar recursos j√° existentes na infraestrutura.  

## **2. Configura√ß√£o do Ambiente no Windows 11**  

## **2.1. Instalando o Terraform**  

1Ô∏è‚É£ Baixe o Terraform em [terraform.io/downloads](https://developer.hashicorp.com/terraform/downloads).  
2Ô∏è‚É£ Extraia e adicione o caminho do Terraform ao **Path do Windows**.  
3Ô∏è‚É£ Confirme a instala√ß√£o com:  
   ```sh
   terraform version
   ```

O comando deve gerar uma sa√≠da semelhante √†:

```text
Terraform v1.11.2
on windows_amd64
```
 
## **2.2. Instalando o Docker Desktop**  
Baixe e instale o Docker Desktop: [docker.com](https://www.docker.com/products/docker-desktop/).  

üö® **Importante:** Ative o suporte a **WSL 2** durante a instala√ß√£o.  

---

## 2.3 Instalando o AWS Cli 


**Utilizando o Chocolatey**

```
choco install awscli
```

```
aws --version
```

```
aws-cli/2.24.25 Python/3.12.9 Windows/11 exe/AMD64
```

**Manualmente** 

Baixe e instale o AWS CLI:  
üîó [Download do AWS CLI v2](https://awscli.amazonaws.com/AWSCLIV2.msi)

1Ô∏è‚É£ Execute o instalador (`AWSCLIV2.msi`).  
2Ô∏è‚É£ Conclua a instala√ß√£o e reinicie o computador.  
3Ô∏è‚É£ Verifique a instala√ß√£o novamente com:  
   ```sh
   aws --version
   ```

** Adicionar o AWS CLI ao PATH (se necess√°rio)**  

Se o comando `aws --version` ainda n√£o for reconhecido:  

1Ô∏è‚É£ **Abra o Explorador de Arquivos** e v√° para:  
   ```
   C:\Program Files\Amazon\AWSCLIV2\
   ```
2Ô∏è‚É£ Copie o caminho completo, por exemplo:  
   ```
   C:\Program Files\Amazon\AWSCLIV2\
   ```
3Ô∏è‚É£ No **Painel de Controle**, v√° para:  
   ```
   Sistema ‚Üí Configura√ß√µes Avan√ßadas ‚Üí Vari√°veis de Ambiente
   ```
4Ô∏è‚É£ Na vari√°vel `Path`, clique em **Editar** e **Adicione o caminho copiado**.  
5Ô∏è‚É£ Clique em **OK** e reinicie o computador.  


---

## 2.4 Configurando o LocalStack para Simular o S3

O **LocalStack** √© uma ferramenta que simula servi√ßos AWS localmente.  


1. Suba o container do LocalStack:  

    Executando em modo interativo

   ```sh
   docker run --name localstack --rm -it -p 4566:4566 localstack/localstack
   ```
   ou  executando em modo Daemon 
   
   ```sh
   docker run --name localstack -d -it -p 4566:4566 localstack/localstack
   ```
   
   ```
   docker ps
   ```
   
   
1.  Configurar Credenciais para o LocalStack

    ```powershell
    aws configure
    ```
    
    Informe os valores de teste
    
    ```text
    AWS Access Key ID [None]: test
    AWS Secret Access Key [None]: test
    Default region name [None]: us-east-1
    Default output format [None]: json

    ```
    
 1. Configura√ß√£o Tempor√°ria

    Se voc√™ n√£o quiser salvar as credenciais globalmente, defina-as apenas para a sess√£o atual:

    No PowerShell, execute:

    ```bash
    $env:AWS_ACCESS_KEY_ID="test"
    $env:AWS_SECRET_ACCESS_KEY="test"
    $env:AWS_DEFAULT_REGION="us-east-1"
    ```
    Ou, no cmd:
    
    ```bash
    set AWS_ACCESS_KEY_ID=test
    set AWS_SECRET_ACCESS_KEY=test
    set AWS_DEFAULT_REGION=us-east-1
    ```
   
 1. Crie um bucket S3 no LocalStack para armazenar o estado remoto:  
 
    ```sh
    aws --endpoint-url=http://localhost:4566 s3 mb s3://meu-terraform-state
    ```
    
    O comando deve gerar uma sa√≠da semelhante √†:
    
    ```text
    make_bucket: meu-terraform-state
    ```
   
    Para listar os Buckets utilize o comando abaixo:
   
    ```
    aws --endpoint-url=http://localhost:4566 s3 ls
    ```

# 3. Criando um M√≥dulo Reutiliz√°vel no Terraform

## **3.1. Estrutura do M√≥dulo**  

Crie uma pasta chamada **terraform-modules** e dentro dela crie o m√≥dulo **"analyze-environment"**:  

```
terraform-atividade02/
‚îÇ‚îÄ‚îÄ analyze-environment/
‚îÇ   ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
```

```
d:
mkdir D:\_devops\terraform-atividade02\analyze-environment
cd D:\_devops\terraform-atividade02\analyze-environment
```


üìå **main.tf** (Define um container Docker como ambiente de an√°lise)  

```powershell
code main.tf
```

```text
terraform {
  required_providers {
    docker = {
      source  = "kreuzwerker/docker"
      version = "~> 3.0.2"
    }
  }
}

#provider "docker" {}

resource "docker_network" "analysis_net" {
  name = "analysis_network"
}

resource "docker_container" "jupyter" {
  name  = var.jupyter_name
  image = "jupyter/datascience-notebook"
  ports {
    internal = 8888
    external = var.jupyter_port
  }
  networks_advanced {
    name = docker_network.analysis_net.name
  }
}

resource "docker_container" "postgres" {
  name  = var.postgres_name
  image = "postgres:15"
  env = [
    "POSTGRES_USER=${var.db_user}",
    "POSTGRES_PASSWORD=${var.db_password}",
    "POSTGRES_DB=${var.db_name}"
  ]
  ports {
    internal = 5432
    external = var.postgres_port
  }
  networks_advanced {
    name = docker_network.analysis_net.name
  }
}

resource "docker_container" "minio" {
  name  = var.minio_name
  image = "minio/minio"
  command = ["server", "/data"]
  env = [
    "MINIO_ACCESS_KEY=${var.minio_access_key}",
    "MINIO_SECRET_KEY=${var.minio_secret_key}"
  ]
  ports {
    internal = 9000
    external = var.minio_port
  }
  networks_advanced {
    name = docker_network.analysis_net.name
  }
}

```

üìå **variables.tf** (Vari√°veis do m√≥dulo)  

```
code variables.tf
```


```text
variable "jupyter_name" { default = "jupyter-notebook" }
variable "jupyter_port" { default = 8888 }
variable "postgres_name" { default = "postgres-db" }
variable "postgres_port" { default = 5432 }
variable "db_user" { default = "admin" }
variable "db_password" { default = "password" }
variable "db_name" { default = "analytics" }
variable "minio_name" { default = "minio-storage" }
variable "minio_port" { default = 9000 }
variable "minio_access_key" { default = "minioadmin" }
variable "minio_secret_key" { default = "minioadmin" }
```

üìå **outputs.tf** (Sa√≠da do m√≥dulo)  

```
code outputs.tf
```


```hcl
output "jupyter_url" {
  value = "http://localhost:${var.jupyter_port}"
}

output "postgres_host" {
  value = "localhost:${var.postgres_port}"
}

output "minio_console" {
  value = "http://localhost:${var.minio_port}"
}
```

---

# **4. Gerenciando o Estado do Terraform com Backend Remoto**  

## **4.1. Configura√ß√£o do Backend Remoto**  

```
cd ..
code backend.tf
```


No diret√≥rio principal, crie um **backend.tf**:  

```hcl
terraform {
  backend "s3" {
    bucket                      = "meu-terraform-state"
    key                         = "terraform.tfstate"
    region                      = "us-east-1"
    endpoints = {
      s3 = "http://127.0.0.1:4566"
    }
    skip_credentials_validation = true
    skip_metadata_api_check     = true
    use_path_style              = true
    skip_requesting_account_id  = true
  }
}
```

## **4.2. Inicializando o Backend**  

Execute:  
```sh
terraform init
```

Se tudo estiver correto, o Terraform armazenar√° o estado no **LocalStack S3**.

```
Initializing the backend...

Successfully configured the backend "s3"! Terraform will automatically
use this backend unless the backend configuration changes.
Initializing provider plugins...

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
```

---


# **5. Implementando Workspaces**  

Workspaces permitem gerenciar m√∫ltiplos ambientes sem alterar o c√≥digo.

## **5.1. Criando e Alternando Workspaces**  

üìå Criar um novo workspace:  
```sh
terraform workspace new desenvolvimento
```

```text
Created and switched to workspace "desenvolvimento"!

You're now on a new, empty workspace. Workspaces isolate their state,
so if you run "terraform plan" Terraform will not see any existing state
for this configuratio
```


üìå Alternar entre workspaces:  
```sh
terraform workspace select desenvolvimento
```

üìå Verificar workspaces dispon√≠veis:  
```sh
terraform workspace list
```

O comando deve gerar uma sa√≠da semelhante √† :

```
  default
* desenvolvimento
```

Agora, cada workspace ter√° seu pr√≥prio estado.

---

# **6. Usando Data Sources para Consultar Recursos Existentes**  

O **data source** permite consultar recursos j√° criados.

## **6.1. Consultando um Bucket S3 Existente**  

Adicione no `main.tf` principal:  

```powershell
code main.tf
```

```text
provider "aws" {
  region                      = "us-east-1"
  access_key                  = "test"  # Credenciais fict√≠cias
  secret_key                  = "test"  # Credenciais fict√≠cias
  skip_credentials_validation = true
  skip_metadata_api_check     = true
  skip_requesting_account_id  = true

  # Configura√ß√£o correta do endpoint para LocalStack
  endpoints {
    s3 = "http://127.0.0.1:4566"
  }
}



# Cria√ß√£o do bucket
resource "aws_s3_bucket" "meu_state_bucket" {
  bucket = "meu-terraform-state-unique"
}

# ACL separada para o bucket
resource "aws_s3_bucket_acl" "meu_state_bucket_acl" {
  bucket = aws_s3_bucket.meu_state_bucket.id
  acl    = "private"
}

# Referenciar o bucket
data "aws_s3_bucket" "state_bucket" {
  bucket = aws_s3_bucket.meu_state_bucket.bucket
}

output "bucket_name" {
  value = data.aws_s3_bucket.state_bucket.bucket
}


module "analyze-environment" {
  source = "./analyze-environment"  # Caminho para o m√≥dulo  
}
```

---


# **7. Testando a Infraestrutura**  

## **7.1. Aplicando as Configura√ß√µes**  

1. Inicie o Terraform:  
   ```sh
   terraform init
   ```  
   
    ``` text
    Initializing the backend...
    Initializing modules...
    - analyze-environment in analyze-environment
    Initializing provider plugins...
    - Finding latest version of hashicorp/aws...
    - Finding kreuzwerker/docker versions matching "~> 3.0.2"...
    - Installing kreuzwerker/docker v3.0.2...
    - Installed kreuzwerker/docker v3.0.2 (self-signed, key ID BD080C4571C6104C)
    - Installing hashicorp/aws v5.91.0...
    - Installed hashicorp/aws v5.91.0 (signed by HashiCorp)
    Partner and community providers are signed by their developers.
    If you'd like to know more about provider signing, you can read about it here:
    https://www.terraform.io/docs/cli/plugins/signing.html
    Terraform has created a lock file .terraform.lock.hcl to record the provider
    selections it made above. Include this file in your version control repository
    so that Terraform can guarantee to make the same selections by default when
    you run "terraform init" in the future.
    
    Terraform has been successfully initialized!
    
    You may now begin working with Terraform. Try running "terraform plan" to see
    any changes that are required for your infrastructure. All Terraform commands
    should now work.
    
    If you ever set or change modules or backend configuration for Terraform,
    rerun this command to reinitialize your working directory. If you forget, other
    commands will detect it and remind you to do so if necessary.
    ```
   
  
1. Execute o plano para visualizar as mudan√ßas:  
   ```sh
   terraform plan
   ```  
   
    ```text
    Terraform used the selected providers to generate the following execution plan. Resource
    actions are indicated with the following symbols:
      + create
     <= read (data resources)
    
    Terraform will perform the following actions:
    
      # data.aws_s3_bucket.state_bucket will be read during apply
      # (depends on a resource or a module with changes pending)
     <= data "aws_s3_bucket" "state_bucket" {
          + arn                         = (known after apply)
          + bucket                      = "meu-terraform-state-unique"
          + bucket_domain_name          = (known after apply)
          + bucket_regional_domain_name = (known after apply)
          + hosted_zone_id              = (known after apply)
          + id                          = (known after apply)
          + region                      = (known after apply)
          + website_domain              = (known after apply)
          + website_endpoint            = (known after apply)
        }
    
      # aws_s3_bucket.meu_state_bucket will be created
      + resource "aws_s3_bucket" "meu_state_bucket" {
          + acceleration_status         = (known after apply)
          + acl                         = (known after apply)
          + arn                         = (known after apply)
          + bucket                      = "meu-terraform-state-unique"
          + bucket_domain_name          = (known after apply)
          + bucket_prefix               = (known after apply)
          + bucket_regional_domain_name = (known after apply)
          + force_destroy               = false
          + hosted_zone_id              = (known after apply)
          + id                          = (known after apply)
          + object_lock_enabled         = (known after apply)
          + policy                      = (known after apply)
          + region                      = (known after apply)
          + request_payer               = (known after apply)
          + tags_all                    = (known after apply)
          + website_domain              = (known after apply)
          + website_endpoint            = (known after apply)
    
          + cors_rule (known after apply)
    
          + grant (known after apply)
    
          + lifecycle_rule (known after apply)
    
          + logging (known after apply)
    
          + object_lock_configuration (known after apply)
    
          + replication_configuration (known after apply)
    
          + server_side_encryption_configuration (known after apply)
    
          + versioning (known after apply)
    
          + website (known after apply)
        }
    
      # aws_s3_bucket_acl.meu_state_bucket_acl will be created
      + resource "aws_s3_bucket_acl" "meu_state_bucket_acl" {
          + acl    = "private"
          + bucket = (known after apply)
          + id     = (known after apply)
    
          + access_control_policy (known after apply)
        }
    
      # module.analyze-environment.docker_container.jupyter will be created
      + resource "docker_container" "jupyter" {
          + attach                                      = false
          + bridge                                      = (known after apply)
          + command                                     = (known after apply)
          + container_logs                              = (known after apply)
          + container_read_refresh_timeout_milliseconds = 15000
          + entrypoint                                  = (known after apply)
          + env                                         = (known after apply)
          + exit_code                                   = (known after apply)
          + hostname                                    = (known after apply)
          + id                                          = (known after apply)
          + image                                       = "jupyter/datascience-notebook"
          + init                                        = (known after apply)
          + ipc_mode                                    = (known after apply)
          + log_driver                                  = (known after apply)
          + logs                                        = false
          + must_run                                    = true
          + name                                        = "jupyter-notebook"
          + network_data                                = (known after apply)
          + read_only                                   = false
          + remove_volumes                              = true
          + restart                                     = "no"
          + rm                                          = false
          + runtime                                     = (known after apply)
          + security_opts                               = (known after apply)
          + shm_size                                    = (known after apply)
          + start                                       = true
          + stdin_open                                  = false
          + stop_signal                                 = (known after apply)
          + stop_timeout                                = (known after apply)
          + tty                                         = false
          + wait                                        = false
          + wait_timeout                                = 60
    
          + healthcheck (known after apply)
    
          + labels (known after apply)
    
          + networks_advanced {
              + aliases      = []
              + name         = "analysis_network"
                # (2 unchanged attributes hidden)
            }
    
          + ports {
              + external = 8888
              + internal = 8888
              + ip       = "0.0.0.0"
              + protocol = "tcp"
            }
        }
    
      # module.analyze-environment.docker_container.minio will be created
      + resource "docker_container" "minio" {
          + attach                                      = false
          + bridge                                      = (known after apply)
          + command                                     = [
              + "server",
              + "/data",
            ]
          + container_logs                              = (known after apply)
          + container_read_refresh_timeout_milliseconds = 15000
          + entrypoint                                  = (known after apply)
          + env                                         = [
              + "MINIO_ACCESS_KEY=minioadmin",
              + "MINIO_SECRET_KEY=minioadmin",
            ]
          + exit_code                                   = (known after apply)
          + hostname                                    = (known after apply)
          + id                                          = (known after apply)
          + image                                       = "minio/minio"
          + init                                        = (known after apply)
          + ipc_mode                                    = (known after apply)
          + log_driver                                  = (known after apply)
          + logs                                        = false
          + must_run                                    = true
          + name                                        = "minio-storage"
          + network_data                                = (known after apply)
          + read_only                                   = false
          + remove_volumes                              = true
          + restart                                     = "no"
          + rm                                          = false
          + runtime                                     = (known after apply)
          + security_opts                               = (known after apply)
          + shm_size                                    = (known after apply)
          + start                                       = true
          + stdin_open                                  = false
          + stop_signal                                 = (known after apply)
          + stop_timeout                                = (known after apply)
          + tty                                         = false
          + wait                                        = false
          + wait_timeout                                = 60
    
          + healthcheck (known after apply)
    
          + labels (known after apply)
    
          + networks_advanced {
              + aliases      = []
              + name         = "analysis_network"
                # (2 unchanged attributes hidden)
            }
    
          + ports {
              + external = 9000
              + internal = 9000
              + ip       = "0.0.0.0"
              + protocol = "tcp"
            }
        }
    
      # module.analyze-environment.docker_container.postgres will be created
      + resource "docker_container" "postgres" {
          + attach                                      = false
          + bridge                                      = (known after apply)
          + command                                     = (known after apply)
          + container_logs                              = (known after apply)
          + container_read_refresh_timeout_milliseconds = 15000
          + entrypoint                                  = (known after apply)
          + env                                         = [
              + "POSTGRES_DB=analytics",
              + "POSTGRES_PASSWORD=password",
              + "POSTGRES_USER=admin",
            ]
          + exit_code                                   = (known after apply)
          + hostname                                    = (known after apply)
          + id                                          = (known after apply)
          + image                                       = "postgres:15"
          + init                                        = (known after apply)
          + ipc_mode                                    = (known after apply)
          + log_driver                                  = (known after apply)
          + logs                                        = false
          + must_run                                    = true
          + name                                        = "postgres-db"
          + network_data                                = (known after apply)
          + read_only                                   = false
          + remove_volumes                              = true
          + restart                                     = "no"
          + rm                                          = false
          + runtime                                     = (known after apply)
          + security_opts                               = (known after apply)
          + shm_size                                    = (known after apply)
          + start                                       = true
          + stdin_open                                  = false
          + stop_signal                                 = (known after apply)
          + stop_timeout                                = (known after apply)
          + tty                                         = false
          + wait                                        = false
          + wait_timeout                                = 60
    
          + healthcheck (known after apply)
    
          + labels (known after apply)
    
          + networks_advanced {
              + aliases      = []
              + name         = "analysis_network"
                # (2 unchanged attributes hidden)
            }
    
          + ports {
              + external = 5432
              + internal = 5432
              + ip       = "0.0.0.0"
              + protocol = "tcp"
            }
        }
    
      # module.analyze-environment.docker_network.analysis_net will be created
      + resource "docker_network" "analysis_net" {
          + driver      = (known after apply)
          + id          = (known after apply)
          + internal    = (known after apply)
          + ipam_driver = "default"
          + name        = "analysis_network"
          + options     = (known after apply)
          + scope       = (known after apply)
    
          + ipam_config (known after apply)
        }
    
    Plan: 6 to add, 0 to change, 0 to destroy.
    
    Changes to Outputs:
      + bucket_name = "meu-terraform-state-unique"
    
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
    Note: You didn't use the -out option to save this plan, so Terraform can't guarantee to take
    exactly these actions if you run "terraform apply" now.
    ```

1. Aplique a infraestrutura:  


   ```sh
   #aws --endpoint-url=http://localhost:4566 s3 rb s3://meu-terraform-state --force
   terraform apply -auto-approve
   ```
   
## 7.2 Acessando o Jupyter

```powershell
docker ps -a 
docker logs jupyter-notebook
```

```
To access the server, open this file in a browser:
    file:///home/jovyan/.local/share/jupyter/runtime/jpserver-7-open.html
Or copy and paste one of these URLs:
    http://13e97a5b5ca8:8888/lab?token=4b0bcfa7e9b1c5dc5a5331353f8da375b5edcaacd7510019
    http://127.0.0.1:8888/lab?token=4b0bcfa7e9b1c5dc5a5331353f8da375b5edcaacd7510019
```


## 7.3 Destuindo os Recursos

Para remover tudo:  
```sh
terraform destroy -auto-approve
```

--- 